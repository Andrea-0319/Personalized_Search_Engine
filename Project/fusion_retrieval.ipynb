{"cells":[{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"268086434e0d4649a94b7dec4836b18e","deepnote_cell_type":"text-cell-h1"},"source":"# Fusion Retrieval with Reciprocal Rank Fusion (RRF)","block_group":"99de3cb272784c6abb372c5fdf6f43d8"},{"cell_type":"code","metadata":{"source_hash":"8cc09de7","execution_start":1740415051438,"execution_millis":5069,"execution_context_id":"b87ef26d-e5a0-4957-86c7-b040719229db","cell_id":"676d2c0699834a65acfc2b630dd16bee","deepnote_cell_type":"code"},"source":"import sys\nsys.path.append('/work/utilis')\n\nfrom lib_to_use import *\nfrom general_functions import *\nfrom paths import *","block_group":"c1f6053c9d454dc7acc2a3334074cd77","execution_count":1,"outputs":[{"name":"stderr","text":"/root/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\nTorch version:  2.6.0+cu124\nPyterrier version:  0.13.0\n/work/utilis/lib_to_use.py:32: FutureWarning: The demoji.download_codes attribute is deprecated and will be removed from demoji in a future version. It is an unused attribute as emoji codes are now distributed directly with the demoji package.\n  demoji.download_codes()\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/2f8616cd-1745-4066-a7d9-ecc8eced17f4","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"585ac0f8","execution_start":1740415056554,"execution_millis":530,"execution_context_id":"b87ef26d-e5a0-4957-86c7-b040719229db","cell_id":"081b280119dd400398dc6fa34ca96f9b","deepnote_cell_type":"code"},"source":"qrels_train = load_qrels(qrels_train_path)\nqrels_val = load_qrels(qrels_val_path)\nqrels_test = load_qrels(qrels_test_path)\nqrels_train_df = qrels_to_df(qrels_train)\nqrels_val_df = qrels_to_df(qrels_val)\nqrels_test_df = qrels_to_df(qrels_test)","block_group":"f7fea863f3804d03bc52468eb8e56d0e","execution_count":2,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"26edd0c2","execution_start":1740415057134,"execution_millis":4331,"execution_context_id":"b87ef26d-e5a0-4957-86c7-b040719229db","cell_id":"e29c66e27f85480eb3770773d081854b","deepnote_cell_type":"code"},"source":"with open(test_processed_path, \"rb\") as f:\n    df_test = pickle.load(f)\n\nwith open(val_processed_path, \"rb\") as f:\n    df_val = pickle.load(f)\n\nwith open(train_processed_path, \"rb\") as f:\n    df_train = pickle.load(f)\n\nwith open(\"/work/PIR_data_unzip/PIR_data/answer_retrieval/df_all_processed.pkl\", \"rb\") as f:\n    df_all = pickle.load(f)\n# Create a PyTerrier index\nindex_path = \"./pyterrier_index\"\n# indexer = pt.IterDictIndexer(index_path, overwrite=True,meta={'docno': 50, 'text': 10000})\n\n# # Index only the document collection (answers)\n# corpus = df_all[['docno', 'text']].to_dict('records')\n# # rimuovi i duplicati docno\n# index_ref = indexer.index(corpus)\n\n# Load the index previously built (using the IndexFactory)\nindex_ref = pt.IndexFactory.of(index_path)","block_group":"669ec605ba8d40b18ebccd278a2f11a9","execution_count":3,"outputs":[{"name":"stderr","text":"Java started (triggered by IndexFactory.of) and loaded: pyterrier.java, pyterrier.terrier.java [version=5.11 (build: craig.macdonald 2025-01-13 21:29), helper_version=0.0.8]\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/426f9d2e-b86e-4428-8d0e-500a57d6869b","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"da13c031","execution_start":1740415061514,"execution_millis":593,"execution_context_id":"b87ef26d-e5a0-4957-86c7-b040719229db","cell_id":"3729082addfd4e1f89086a61b6e45f6e","deepnote_cell_type":"code"},"source":"# Carica i risultati dei modelli in DataFrame\n# Si assume che ogni DataFrame abbia le colonne: 'qid', 'docno' e 'score'\nwith open('/work/PIR_data_unzip/PIR_data/answer_retrieval/saved_results/bm25_optimized_results.pkl', 'rb') as f:\n    results_bm25 =  pickle.load(f)\n\nwith open('/work/PIR_data_unzip/PIR_data/answer_retrieval/saved_results/bm25_minilm_results.pkl', 'rb') as f:\n    results_bm25_minilm =  pickle.load(f)\n\nwith open('/work/PIR_data_unzip/PIR_data/answer_retrieval/saved_results/bm25_distilbert_qa_results.pkl', 'rb') as f:\n    results_bm25_distilbertqa =  pickle.load(f)\n\nwith open('/work/PIR_data_unzip/PIR_data/answer_retrieval/saved_results/bm25_T5_results.pkl', 'rb') as f:\n    results_bm25_t5 =  pickle.load(f)","block_group":"6359208233084551a724ec29b0f984b5","execution_count":4,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"250ebbcd","execution_start":1740415062154,"execution_millis":1,"execution_context_id":"b87ef26d-e5a0-4957-86c7-b040719229db","cell_id":"edef691f44f94c9b8e1c1e1b3e6acec2","deepnote_cell_type":"code"},"source":"def assign_rank(df):\n    \"\"\"\n    Assigns a rank to each document per query based on the 'score' in descending order.\n    \"\"\"\n    df = df.copy()\n    df['rank'] = df.groupby('qid')['score'].rank(method='min', ascending=False)\n    return df\n\ndef compute_rrf(df, k=200):\n    \"\"\"\n    Calcola il Reciprocal Rank Fusion (RRF) score per documento.\n    RRF = 1 / (k + rank)\n    \"\"\"\n    df = assign_rank(df)\n    df['rrf'] = 1.0 / (k + df['rank'])\n    return df[['qid', 'docno', 'rrf']]\n\n# Calcola i punteggi RRF per ogni sistema\nbm25_rrf = compute_rrf(results_bm25, k=60)\nminilm_rrf = compute_rrf(results_bm25_minilm, k=60)\ndistilbert_rrf = compute_rrf(results_bm25_distilbertqa, k=60)\nt5_rrf = compute_rrf(results_bm25_t5, k=60)","block_group":"f7b885ff8fc9425b82861e9022b3de95","execution_count":5,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"2a9e7ee5","execution_start":1740415062202,"execution_millis":369,"execution_context_id":"b87ef26d-e5a0-4957-86c7-b040719229db","cell_id":"729f4c7566cf437f8c17f29854959e77","deepnote_cell_type":"code"},"source":"# Unisci i risultati: creiamo un DataFrame con l'unione dei docno per ogni query\nall_results = pd.concat([bm25_rrf, minilm_rrf, distilbert_rrf, t5_rrf])\n\n# Per ogni coppia (qid, docno), somma i punteggi RRF provenienti dai vari sistemi\nfusion_scores = all_results.groupby(['qid', 'docno'], as_index=False)['rrf'].sum()\n\n# Ordina i risultati finali per ogni query in base al punteggio di fusione (dal pi√π alto al pi√π basso)\nfusion_scores = fusion_scores.sort_values(['qid', 'rrf'], ascending=[True, False])\n\nwith open ('/work/PIR_data_unzip/PIR_data/answer_retrieval/saved_results/fusion_results.pkl', 'wb') as f:\n    pickle.dump(fusion_scores, f)\n\n# Visualizza i risultati finali\nprint(\"Risultati della fusion retrieval:\")\nfusion_scores","block_group":"e73bcf757be348d3b335c668d1c38c55","execution_count":6,"outputs":[{"name":"stdout","text":"Risultati della fusion retrieval:\n","output_type":"stream"},{"output_type":"execute_result","execution_count":6,"data":{"application/vnd.deepnote.dataframe.v3+json":{"column_count":3,"row_count":95448,"columns":[{"name":"qid","dtype":"object","stats":{"unique_count":96,"nan_count":0,"categories":[{"name":"academia_143743","count":1000},{"name":"academia_148899","count":1000},{"name":"94 others","count":93448}]}},{"name":"docno","dtype":"object"},{"name":"rrf","dtype":"float64"},{"name":"_deepnote_index_column","dtype":"int64"}],"rows":[{"qid":"academia_143743","docno":"academia_12035","rrf":0.06063970702820633,"_deepnote_index_column":6},{"qid":"academia_143743","docno":"workplace_9502","rrf":0.06049915488905672,"_deepnote_index_column":961},{"qid":"academia_143743","docno":"scifi_117801","rrf":0.05997557997557998,"_deepnote_index_column":779},{"qid":"academia_143743","docno":"academia_122342","rrf":0.0589109079166525,"_deepnote_index_column":7},{"qid":"academia_143743","docno":"workplace_102543","rrf":0.058897801544860365,"_deepnote_index_column":925},{"qid":"academia_143743","docno":"academia_28111","rrf":0.05653688524590164,"_deepnote_index_column":28},{"qid":"academia_143743","docno":"philosophy_23588","rrf":0.05381057410222917,"_deepnote_index_column":634},{"qid":"academia_143743","docno":"academia_143753","rrf":0.05220436097405698,"_deepnote_index_column":13},{"qid":"academia_143743","docno":"workplace_92460","rrf":0.05190496914068682,"_deepnote_index_column":960},{"qid":"academia_143743","docno":"buddhism_5610","rrf":0.050316455696202536,"_deepnote_index_column":134}]},"text/plain":"                   qid             docno       rrf\n6      academia_143743    academia_12035  0.060640\n961    academia_143743    workplace_9502  0.060499\n779    academia_143743      scifi_117801  0.059976\n7      academia_143743   academia_122342  0.058911\n925    academia_143743  workplace_102543  0.058898\n...                ...               ...       ...\n94932    writers_51676  martialarts_7575  0.000947\n95202    writers_51676       scifi_22958  0.000946\n94957    writers_51676      movies_17810  0.000945\n94527    writers_51676       anime_49100  0.000944\n95247    writers_51676    skeptics_23972  0.000943\n\n[95448 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>qid</th>\n      <th>docno</th>\n      <th>rrf</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6</th>\n      <td>academia_143743</td>\n      <td>academia_12035</td>\n      <td>0.060640</td>\n    </tr>\n    <tr>\n      <th>961</th>\n      <td>academia_143743</td>\n      <td>workplace_9502</td>\n      <td>0.060499</td>\n    </tr>\n    <tr>\n      <th>779</th>\n      <td>academia_143743</td>\n      <td>scifi_117801</td>\n      <td>0.059976</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>academia_143743</td>\n      <td>academia_122342</td>\n      <td>0.058911</td>\n    </tr>\n    <tr>\n      <th>925</th>\n      <td>academia_143743</td>\n      <td>workplace_102543</td>\n      <td>0.058898</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>94932</th>\n      <td>writers_51676</td>\n      <td>martialarts_7575</td>\n      <td>0.000947</td>\n    </tr>\n    <tr>\n      <th>95202</th>\n      <td>writers_51676</td>\n      <td>scifi_22958</td>\n      <td>0.000946</td>\n    </tr>\n    <tr>\n      <th>94957</th>\n      <td>writers_51676</td>\n      <td>movies_17810</td>\n      <td>0.000945</td>\n    </tr>\n    <tr>\n      <th>94527</th>\n      <td>writers_51676</td>\n      <td>anime_49100</td>\n      <td>0.000944</td>\n    </tr>\n    <tr>\n      <th>95247</th>\n      <td>writers_51676</td>\n      <td>skeptics_23972</td>\n      <td>0.000943</td>\n    </tr>\n  </tbody>\n</table>\n<p>95448 rows √ó 3 columns</p>\n</div>"},"metadata":{}}],"outputs_reference":"s3:deepnote-cell-outputs-production/89cf4775-d49b-4777-85a6-8246b73603df","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"dcc5e277","execution_start":1740415062618,"execution_millis":151,"execution_context_id":"b87ef26d-e5a0-4957-86c7-b040719229db","cell_id":"3a75f9d577bc4eabbb6d66c40ee85fa5","deepnote_cell_type":"code"},"source":"# # Per valutare i risultati Fusion Scores\n# Rename the columns of fusion_scores to match PyTerrier's expected run format\nfusion_scores_eval = fusion_scores.rename(columns={'query_id': 'qid', 'doc_id': 'docno', 'rrf': 'score'})\n\n# Now evaluate the fused run using PyTerrier's Evaluate function\neval_fusion = pt.Evaluate(fusion_scores_eval, qrels_val_df, metrics=[\"P_1\", \"recall_100\", \"map_cut_100\", \"ndcg_cut_3\"])\nprint(\"Fusion Evaluation:\", eval_fusion)","block_group":"6b1d7ca32590480497256acc7cbf503c","execution_count":7,"outputs":[{"name":"stdout","text":"Fusion Evaluation: {'P_1': 0.673469387755102, 'recall_100': 0.9285714285714286, 'map_cut_100': 0.7243080618176241, 'ndcg_cut_3': 0.7171997808309056}\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/29184113-1646-49d1-bb79-735398cb1996","content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"32b933a91dba4a6b9a1771cd212e8098","deepnote_cell_type":"markdown"},"source":"The core idea behind RRF is that each document receives a score inversely proportional to its rank in each system. These scores are then summed across systems to obtain a final ranking. This method is robust because it relies solely on the rank positions rather than the raw scores, which might be on different scales.","block_group":"153133f4a2e145e082a3fa040224f527"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"13465e8ffd074bd3bedcb5558373f9db","deepnote_cell_type":"text-cell-h2"},"source":"## Assigning Ranks to Results","block_group":"4ac7c4cf5748490187daa2b6b02f4028"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"2600ccf97818499fbe65350d080e745c","deepnote_cell_type":"text-cell-p"},"source":"The assign_rank function checks whether the input DataFrame already has a \"rank\" column. If not, it computes the rank for each query group (grouped by \"qid\") based on the \"score\" column, ordering in descending order (so that the highest score gets rank 1).\r","block_group":"7dc328cac94747519f34edd43c13dd15"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"9c6cd6a0a69b4bc4b0a9a65916a722e2","deepnote_cell_type":"text-cell-h2"},"source":"## Computing the RRF Score","block_group":"a3a1528f49e14f5c89259af2703faf31"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"a2943e76a5cd489081705b49c160140b","deepnote_cell_type":"text-cell-p"},"source":"The compute_rrf function takes a DataFrame and calculates the RRF score for each document using the formula:\r\n                         RRF\r= 1\r/(ùëò\r+\rrank).","block_group":"86548395a4604bad84e9d1ecab26c2c8"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"b01ee9ad7f6b455285527131f71dfe28","deepnote_cell_type":"text-cell-p"},"source":"Here,\rùëò is a constant (typically set to 60) that helps control the influence of the rank. Lower ranks (i.e., better-ranked documents) receive higher RRF scores.","block_group":"6b96eccdacb94ed4b5a98d86e80ffad5"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"7d929b36399e4b83b45a395745d6cba4","deepnote_cell_type":"text-cell-h2"},"source":"## Processing Results from Multiple Systems","block_group":"cd79554d50d742e5954bd5a36eca1d6c"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"8fe4cdeb0c274e15abd462d984ba7726","deepnote_cell_type":"text-cell-p"},"source":"For each retrieval system , we assume we have a corresponding DataFrame (e.g., bm25_df, minilm_df, etc.) that contains at least:\r\n- qid: Query identifier;\r\n- docno: Document identifier;\r\n- score: The retrieval score provided by that system;\r\nThe compute_rrf function is applied to each of these DataFrames, producing a new DataFrame that includes the RRF scores.","block_group":"e2a65a49d11b4353bcd65d2380bdbdb2"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"f2644506eeb147c18d73e5566bd1c9ba","deepnote_cell_type":"text-cell-h2"},"source":"## \r\rFusion of the RRF Scores","block_group":"28d74143dad947ebaf98125c3a341f61"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"8d0dc83c4622418ab16dabff2d17a03a","deepnote_cell_type":"text-cell-p"},"source":"All the RRF DataFrames are concatenated into one DataFrame. This combined DataFrame now contains rows from all systems.\r\nThen, we group the combined results by the query and document identifiers (qid and docno) and sum the RRF scores for each group. This gives a final fusion score for each document per query.\r\nFinally, the results are sorted by query and in descending order of the final fusion score.‚Äã","block_group":"434aa4ff46e5458183cceb6b4daa6403"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"315ba162490f4f8ab50e93bccf5c4611","deepnote_cell_type":"text-cell-h2"},"source":"## Why Use This Approach?","block_group":"0a0e70c524a74c45a20b5036f9f0d07a"},{"cell_type":"markdown","metadata":{"cell_id":"79913c30b5a344d98bec261e2b044a19","deepnote_cell_type":"markdown"},"source":"- **Robustness**: RRF does not depend on the absolute values of the scores from different systems but rather on the rank positions. This makes it effective when the underlying systems use different scoring scales.\n- **Consensus Boost**: Documents that consistently appear at high ranks across multiple systems will accumulate higher scores, thus improving their final rank.\n- **Simplicity**: RRF is simple to implement and does not require additional training data.","block_group":"8427766f95f84b6bba7e7c0ee58e03e0"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"c0089da60e3a4788ade0fa3b957f1142","deepnote_cell_type":"text-cell-h1"},"source":"#  Weighted sum of individual scores","block_group":"fc96d702b196402aad7c03a2a23e7f8e"},{"cell_type":"code","metadata":{"source_hash":"a08414d0","execution_start":1740415062818,"execution_millis":0,"execution_context_id":"b87ef26d-e5a0-4957-86c7-b040719229db","cell_id":"96489ab954164344a3d0f9d3a19fc2dc","deepnote_cell_type":"code"},"source":"# Rename the 'score' columns in each DataFrame to avoid conflicts\nbm25_df = results_bm25.rename(columns={'score': 'bm25_score'})\nminilm_df = results_bm25_minilm.rename(columns={'score': 'minilm_score'})\ndistilbert_df = results_bm25_distilbertqa.rename(columns={'score': 'distilbert_score'})\nt5_df = results_bm25_t5.rename(columns={'score': 't5_score'})","block_group":"3176cbc400d4489b87fd6b85ac529e9f","execution_count":8,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"f4de3170","execution_start":1740415062866,"execution_millis":108,"execution_context_id":"b87ef26d-e5a0-4957-86c7-b040719229db","cell_id":"5fda00da951b4520933530a4c3ebfdb6","deepnote_cell_type":"code"},"source":"# Merge the DataFrames on 'qid' and 'docno'. Use an outer join to capture all documents.\nfusion_df = pd.merge(bm25_df, minilm_df, on=['qid', 'docno'], how='outer')\nfusion_df = pd.merge(fusion_df, distilbert_df, on=['qid', 'docno'], how='outer')\nfusion_df = pd.merge(fusion_df, t5_df, on=['qid', 'docno'], how='outer')\n\n# Fill missing scores with 0\nscore_cols = ['bm25_score', 'minilm_score', 'distilbert_score', 't5_score']\nfusion_df[score_cols] = fusion_df[score_cols].fillna(0)","block_group":"38c4ba3836264242a6753cb9b4b86c74","execution_count":9,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_241/4206209075.py:4: FutureWarning: Passing 'suffixes' which cause duplicate columns {'query_x', 'docid_x', 'rank_x'} in the result is deprecated and will raise a MergeError in a future version.\n  fusion_df = pd.merge(fusion_df, t5_df, on=['qid', 'docno'], how='outer')\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/279695fb-2677-4fa7-a7bd-7a7e0a1bec28","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"e788d37a","execution_start":1740415063022,"execution_millis":0,"execution_context_id":"b87ef26d-e5a0-4957-86c7-b040719229db","cell_id":"68f05bea49b14ff29be6a4570d714994","deepnote_cell_type":"code"},"source":"from sklearn.preprocessing import MinMaxScaler\n\nscore_cols = ['bm25_score', 'minilm_score', 'distilbert_score', 't5_score']\nscaler = MinMaxScaler()\n\n# Fit and transform the score columns directly.\nfusion_df[score_cols] = scaler.fit_transform(fusion_df[score_cols])\nfusion_df[score_cols]","block_group":"64249732600e43dbaad0a46692431905","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"application/vnd.deepnote.dataframe.v3+json":{"column_count":4,"row_count":105432,"columns":[{"name":"bm25_score","dtype":"float64"},{"name":"minilm_score","dtype":"float64"},{"name":"distilbert_score","dtype":"float64"},{"name":"t5_score","dtype":"float64"},{"name":"_deepnote_index_column","dtype":"int64"}],"rows":[{"bm25_score":0.33314555279404706,"minilm_score":0.5065470868433768,"distilbert_score":0.8736017088753026,"t5_score":0.33781051569176235,"_deepnote_index_column":0},{"bm25_score":0.32617893006127285,"minilm_score":0.660269064221438,"distilbert_score":0.8798187697189018,"t5_score":0.3309949191960893,"_deepnote_index_column":1},{"bm25_score":0.2988100961703969,"minilm_score":0.048435427627386285,"distilbert_score":0.8956308763245174,"t5_score":0.30421940177359924,"_deepnote_index_column":2},{"bm25_score":0.29007244354101086,"minilm_score":0.4479504120194928,"distilbert_score":0,"t5_score":0.2956711687307664,"_deepnote_index_column":3},{"bm25_score":0.2585122369023784,"minilm_score":0.6546055224680569,"distilbert_score":0.9017777045650799,"t5_score":0.2647951414188463,"_deepnote_index_column":4},{"bm25_score":0.25079918693489894,"minilm_score":0.7179218642783535,"distilbert_score":0.8787381975127035,"t5_score":0.2572492991440817,"_deepnote_index_column":5},{"bm25_score":0.24677802508390323,"minilm_score":0.5792427398425752,"distilbert_score":0.8623627873962709,"t5_score":0.2533153102270061,"_deepnote_index_column":6},{"bm25_score":0.24568486995925298,"minilm_score":0.048435427627386285,"distilbert_score":0.8529839478828183,"t5_score":0.2522458531137706,"_deepnote_index_column":7},{"bm25_score":0.2429296230630441,"minilm_score":0.8412845154253561,"distilbert_score":0.8932309017158002,"t5_score":0.24955033595849657,"_deepnote_index_column":8},{"bm25_score":0.24109397703515817,"minilm_score":0.3650468915632068,"distilbert_score":0.8504395078917576,"t5_score":0.2477544840637043,"_deepnote_index_column":9}]},"text/plain":"        bm25_score  minilm_score  distilbert_score  t5_score\n0         0.333146      0.506547          0.873602  0.337811\n1         0.326179      0.660269          0.879819  0.330995\n2         0.298810      0.048435          0.895631  0.304219\n3         0.290072      0.447950          0.000000  0.295671\n4         0.258512      0.654606          0.901778  0.264795\n...            ...           ...               ...       ...\n105427    0.049300      0.048435          0.000000  0.000000\n105428    0.049295      0.048435          0.000000  0.000000\n105429    0.049279      0.048435          0.000000  0.000000\n105430    0.049276      0.048435          0.000000  0.000000\n105431    0.049261      0.048435          0.000000  0.000000\n\n[105432 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>bm25_score</th>\n      <th>minilm_score</th>\n      <th>distilbert_score</th>\n      <th>t5_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.333146</td>\n      <td>0.506547</td>\n      <td>0.873602</td>\n      <td>0.337811</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.326179</td>\n      <td>0.660269</td>\n      <td>0.879819</td>\n      <td>0.330995</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.298810</td>\n      <td>0.048435</td>\n      <td>0.895631</td>\n      <td>0.304219</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.290072</td>\n      <td>0.447950</td>\n      <td>0.000000</td>\n      <td>0.295671</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.258512</td>\n      <td>0.654606</td>\n      <td>0.901778</td>\n      <td>0.264795</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>105427</th>\n      <td>0.049300</td>\n      <td>0.048435</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>105428</th>\n      <td>0.049295</td>\n      <td>0.048435</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>105429</th>\n      <td>0.049279</td>\n      <td>0.048435</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>105430</th>\n      <td>0.049276</td>\n      <td>0.048435</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>105431</th>\n      <td>0.049261</td>\n      <td>0.048435</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>105432 rows √ó 4 columns</p>\n</div>"},"metadata":{}}],"outputs_reference":"s3:deepnote-cell-outputs-production/1cfdeb52-4194-4796-9a0c-8b6232a92b0c","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"b6618966","execution_start":1740415063074,"execution_millis":0,"execution_context_id":"b87ef26d-e5a0-4957-86c7-b040719229db","cell_id":"a7550815955d4f55b9ea6d2c5cb4a993","deepnote_cell_type":"code"},"source":"# Define weights based on your evaluation:\nw_bm25 = 0.2\nw_minilm = 0.15\nw_distilbert = 0.15\nw_t5 = 0.5\n\n# Compute the final fused score as a weighted sum of individual scores.\nfusion_df['final_score'] = (\n    w_bm25 * fusion_df['bm25_score'] +\n    w_minilm * fusion_df['minilm_score'] +\n    w_distilbert * fusion_df['distilbert_score'] +\n    w_t5 * fusion_df['t5_score']\n)","block_group":"6a643c76f4134f6190e04c69973f027f","execution_count":11,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"ad19ba66","execution_start":1740415063126,"execution_millis":8,"execution_context_id":"b87ef26d-e5a0-4957-86c7-b040719229db","cell_id":"e74c5e96e29d4be68e3e26d9f199151d","deepnote_cell_type":"code"},"source":"# For each query, sort the documents by final_score in descending order.\nfusion_df = fusion_df.sort_values(['qid', 'final_score'], ascending=[True, False])\n\n# For evaluation with PyTerrier, rename 'final_score' to 'score'\nfusion_df_eval = fusion_df.rename(columns={'final_score': 'score'})","block_group":"be2814a419db4affa42ae21f749f4f49","execution_count":12,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"ba4ded93","execution_start":1740415063182,"execution_millis":0,"execution_context_id":"b87ef26d-e5a0-4957-86c7-b040719229db","cell_id":"436f1494f41c44fa93984430faf039ea","deepnote_cell_type":"code"},"source":"print(\"Final fused retrieval results:\")\nfusion_df_eval[['qid', 'docno', 'score']]\n","block_group":"a13a5bc2cd6c47f69aff8b8eeeed03f0","execution_count":13,"outputs":[{"name":"stdout","text":"Final fused retrieval results:\n","output_type":"stream"},{"output_type":"execute_result","execution_count":13,"data":{"application/vnd.deepnote.dataframe.v3+json":{"column_count":3,"row_count":105432,"columns":[{"name":"qid","dtype":"object"},{"name":"docno","dtype":"object"},{"name":"score","dtype":"float64"},{"name":"_deepnote_index_column","dtype":"int64"}],"rows":[{"qid":"academia_143743","docno":"academia_12035","score":0.4617464207013502,"_deepnote_index_column":1},{"qid":"academia_143743","docno":"academia_28111","score":0.4425566877624925,"_deepnote_index_column":0},{"qid":"academia_143743","docno":"workplace_9502","score":0.43353840516303055,"_deepnote_index_column":8},{"qid":"academia_143743","docno":"academia_122342","score":0.42073321013541826,"_deepnote_index_column":12},{"qid":"academia_143743","docno":"workplace_102543","score":0.4182834962276792,"_deepnote_index_column":5},{"qid":"academia_143743","docno":"scifi_117801","score":0.41755750214486936,"_deepnote_index_column":4},{"qid":"academia_143743","docno":"academia_143753","score":0.4101760912896784,"_deepnote_index_column":42},{"qid":"academia_143743","docno":"philosophy_23588","score":0.3922540892161106,"_deepnote_index_column":6},{"qid":"academia_143743","docno":"workplace_92460","score":0.3860872201030278,"_deepnote_index_column":10},{"qid":"academia_143743","docno":"academia_44220","score":0.38042713444425535,"_deepnote_index_column":26}]},"text/plain":"                   qid             docno     score\n1      academia_143743    academia_12035  0.461746\n0      academia_143743    academia_28111  0.442557\n8      academia_143743    workplace_9502  0.433538\n12     academia_143743   academia_122342  0.420733\n5      academia_143743  workplace_102543  0.418283\n...                ...               ...       ...\n84427    writers_51676  martialarts_7575  0.019931\n84428    writers_51676       scifi_22958  0.019926\n84429    writers_51676      movies_17810  0.019899\n84430    writers_51676       anime_49100  0.019887\n84431    writers_51676    skeptics_23972  0.019874\n\n[105432 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>qid</th>\n      <th>docno</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>academia_143743</td>\n      <td>academia_12035</td>\n      <td>0.461746</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>academia_143743</td>\n      <td>academia_28111</td>\n      <td>0.442557</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>academia_143743</td>\n      <td>workplace_9502</td>\n      <td>0.433538</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>academia_143743</td>\n      <td>academia_122342</td>\n      <td>0.420733</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>academia_143743</td>\n      <td>workplace_102543</td>\n      <td>0.418283</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>84427</th>\n      <td>writers_51676</td>\n      <td>martialarts_7575</td>\n      <td>0.019931</td>\n    </tr>\n    <tr>\n      <th>84428</th>\n      <td>writers_51676</td>\n      <td>scifi_22958</td>\n      <td>0.019926</td>\n    </tr>\n    <tr>\n      <th>84429</th>\n      <td>writers_51676</td>\n      <td>movies_17810</td>\n      <td>0.019899</td>\n    </tr>\n    <tr>\n      <th>84430</th>\n      <td>writers_51676</td>\n      <td>anime_49100</td>\n      <td>0.019887</td>\n    </tr>\n    <tr>\n      <th>84431</th>\n      <td>writers_51676</td>\n      <td>skeptics_23972</td>\n      <td>0.019874</td>\n    </tr>\n  </tbody>\n</table>\n<p>105432 rows √ó 3 columns</p>\n</div>"},"metadata":{}}],"outputs_reference":"s3:deepnote-cell-outputs-production/17ad3211-68ce-47bf-bd8b-7a1e778b3c2c","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"c286a804","execution_start":1740415063234,"execution_millis":276,"execution_context_id":"b87ef26d-e5a0-4957-86c7-b040719229db","cell_id":"266fc8782905441e9cbe6b7400fcecc4","deepnote_cell_type":"code"},"source":"# # Per valutare i risultati Fusion Scores\n# Rename the columns of fusion_scores to match PyTerrier's expected run format\n# fusion_scores_eval = fusion_scores.rename(columns={'query_id': 'qid', 'doc_id': 'docno', 'rrf': 'score'})\n\nfusion_df_eval = fusion_df.rename(columns={'final_score': 'score'})\n\n# Now evaluate the fused run using PyTerrier's Evaluate function\neval_fusion = pt.Evaluate(fusion_df_eval, qrels_val_df, metrics=[\"P_1\", \"recall_100\", \"map_cut_100\", \"ndcg_cut_3\"])\nprint(\"Weighted Fusion Evaluation:\", eval_fusion)","block_group":"ce6346dd56da48e2943c767a1857560c","execution_count":14,"outputs":[{"name":"stdout","text":"Weighted Fusion Evaluation: {'P_1': 0.6938775510204082, 'recall_100': 0.9285714285714286, 'map_cut_100': 0.763168425892842, 'ndcg_cut_3': 0.7735642605685159}\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/02b4d5cf-336e-4e59-869e-7870edbe6bc1","content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"56d16042408e4bb9853e80682681ceb1","deepnote_cell_type":"markdown"},"source":"- w_bm25 = 0.5, w_minilm = 0.15, w_distilbert = 0.15, w_t5 = 0.2\nWeighted Fusion Evaluation: {'P_1': 0.6938775510204082, 'recall_100': 0.9285714285714286, 'map_cut_100': 0.7617532355156883, 'ndcg_cut_3': 0.77599426559767}\n- w_bm25 = 0.4, w_minilm = 0.15, w_distilbert = 0.15, w_t5 = 0.3\nWeighted Fusion Evaluation: {'P_1': 0.7040816326530612, 'recall_100': 0.9285714285714286, 'map_cut_100': 0.769784479719235, 'ndcg_cut_3': 0.7773302834912562}\n- w_bm25 = 0.2, w_minilm = 0.15, w_distilbert = 0.15, w_t5 = 0.5\nWeighted Fusion Evaluation: {'P_1': 0.7142857142857143, 'recall_100': 0.9285714285714286, 'map_cut_100': 0.7750774855809884, 'ndcg_cut_3': 0.7810963064139965}\n","block_group":"dce655e7ec8c40ac95bcc102b920f5db"},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=144ec01f-394f-474f-b507-b786ab13b472' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote_notebook_id":"803f8c8fb17c42f9991bd5d20c56c82a"}}